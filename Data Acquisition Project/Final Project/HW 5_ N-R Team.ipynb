{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/' # Change this \n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output1.csv'  # Changed the extension to .csv\n",
    "\n",
    "# Loading the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        if userID not in train_data:\n",
    "            train_data[userID] = {}\n",
    "        train_data[userID][itemID] = int(rating)\n",
    "\n",
    "# then we process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])  # Into the csv file we will add the header\n",
    "\n",
    "    lastUserID = None  # Track the last user ID processed\n",
    "    trackID_vec = []  # Initialize the track ID vector for each user\n",
    "\n",
    "    for line in fTest:\n",
    "        arr_test = line.strip().split('|')\n",
    "        if len(arr_test) < 4:\n",
    "            continue  # we will skip if  then line doesn't have enough data\n",
    "        userID, trackID, albumID, artistID = arr_test[:4]   # only considering these 4 entities \n",
    "\n",
    "        # Reset trackID_vec for a new user\n",
    "        if userID != lastUserID:\n",
    "            if lastUserID is not None:\n",
    "                # Write predictions for the previous user's tracks\n",
    "                for i, predRating in enumerate(predRatings):\n",
    "                    trackID_pred = f\"{lastUserID}_{trackID_vec[i]}\"\n",
    "                    csv_writer.writerow([trackID_pred, int(predRating > 0)]) \n",
    "\n",
    "            trackID_vec = [trackID]  # Start a new list for the new user\n",
    "            predRatings = np.zeros(6)  # Reset predicted ratings for the new user\n",
    "        else:\n",
    "            trackID_vec.append(trackID)  # Append trackID for the same user\n",
    "\n",
    "        # Check if the user exists in the training data\n",
    "        if userID in train_data:\n",
    "            user_ratings = train_data[userID]\n",
    "\n",
    "            # Predict based on album or artist rating, if available\n",
    "            if albumID in user_ratings:\n",
    "                predRatings[len(trackID_vec) - 1] = user_ratings[albumID]\n",
    "            elif artistID in user_ratings:\n",
    "                predRatings[len(trackID_vec) - 1] = user_ratings[artistID]\n",
    "\n",
    "        lastUserID = userID  # Update the last user ID processed\n",
    "\n",
    "    # Write predictions for the last user in the file\n",
    "    for i, predRating in enumerate(predRatings):\n",
    "        trackID_pred = f\"{userID}_{trackID_vec[i]}\"\n",
    "        csv_writer.writerow([trackID_pred, int(predRating > 0)])  # Write to CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab11bd",
   "metadata": {},
   "source": [
    "### Matrix Factorization with Alternating Least Squares (ALS): Comprehensive Overview\n",
    "\n",
    "#### Motivation:\n",
    "Matrix Factorization using the ALS algorithm is driven by the goal to discover latent factors that elucidate observed ratings in a user-item matrix. This technique is crucial for recommendation systems, particularly effective for large datasets, as it uncovers complex user preferences and item attributes that aren't immediately apparent from observable data like genres or artists. The ALS method is well-suited for addressing both the sparsity of user-item interactions and the scalability challenges in large-scale recommendation systems.\n",
    "\n",
    "#### Formula and Methodology:\n",
    "The ALS algorithm decomposes the user-item rating matrix \\(R\\) into two lower-dimensional matrices, \\(U\\) (user factors) and \\(I\\) (item factors), such that:\n",
    "\\[ R \\approx U \\times I^T \\]\n",
    "This decomposition is achieved by alternately fixing \\(U\\) and \\(I\\) and optimizing the other through iterative updates. The primary goal is to minimize the squared differences between the observed ratings and the product of \\(U\\) and \\(I\\), adjusted for regularization to prevent overfitting:\n",
    "\\[ \\min_{U,I} \\| R - U I^T \\|_F^2 + \\lambda (\\| U \\|_F^2 + \\| I \\|_F^2) \\]\n",
    "Where:\n",
    "- \\( \\lambda \\) is the regularization parameter,\n",
    "- \\( \\|.\\|_F \\) denotes the Frobenius norm,\n",
    "- `maxIter` represents the maximum iterations to refine the model,\n",
    "- `rank` specifies the number of latent factors,\n",
    "- `regParam` controls the regularization strength.\n",
    "\n",
    "#### Discussion:\n",
    "Matrix Factorization through ALS is highly regarded for its efficiency in revealing latent structures within the data, making it a powerful tool in predictive analytics for recommendation systems. It effectively handles large, sparse matrices by inferring user preferences and item characteristics that are not explicitly provided. Key parameters including the rank of the factorization and the number of iterations significantly influence the model's accuracy and computational efficiency. The method's performance is also affected by the `coldStartStrategy`, which is crucial for handling new users or items without historical data. Despite its strengths, ALS requires careful tuning of its hyperparameters to balance between model complexity and overfitting, especially in diverse datasets.\n",
    "\n",
    "### Performance Observations:\n",
    "The ALS model's efficacy is typically measured by the Mean Squared Error (MSE) across various configurations:\n",
    "\n",
    "- **Varying \"Rank\"**: Higher ranks generally improve performance by capturing more detailed underlying structures in the data, but may also risk overfitting.\n",
    "- **Varying \"maxIter\"**: More iterations allow for better convergence to optimal factor matrices, reflected by lower MSE values.\n",
    "- **Varying Data Size**: Larger datasets provide more comprehensive information, allowing for more accurate predictions. However, improvements tend to diminish with excessively large datasets due to inherent noise and complexity.\n",
    "\n",
    "#### Specific Results and Configurations:\n",
    "- **Optimal Settings**: Using a `rank` of 20 and `maxIter` of 20 yielded the best results, indicating an effective level of model complexity and adequate iterations for convergence.\n",
    "- **Data Size Impact**: Increasing the dataset size typically lowers the MSE, indicating better learning of user preferences and item properties, though the rate of improvement decreases with size.\n",
    "\n",
    "#### Conclusion:\n",
    "ALS matrix factorization stands out as a foundational technique in modern recommender systems, essential for extracting deep insights from user-item interactions. Its success hinges on the appropriate selection of hyperparameters and the ability to handle large-scale data efficiently. Continuous refinement of these parameters, based on the dataset characteristics and the specific requirements of the application, is crucial for maximizing the predictive performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc844056",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
