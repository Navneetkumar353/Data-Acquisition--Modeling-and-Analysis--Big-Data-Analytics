{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35a4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "track_info_file = dataDir + 'trackData2.txt'\n",
    "output_file = dataDir + 'output2.csv'\n",
    "\n",
    "# Load training data\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        if userID not in train_data:\n",
    "            train_data[userID] = {}\n",
    "        train_data[userID][itemID] = int(rating)\n",
    "\n",
    "# Load track information (including genres)\n",
    "track_genres = {}\n",
    "with open(track_info_file, 'r') as fTrack:\n",
    "    for line in fTrack:\n",
    "        parts = line.strip().split('|')\n",
    "        trackID, genres = parts[0], parts[3:]\n",
    "        track_genres[trackID] = genres\n",
    "\n",
    "# Function to get genre ratings for a track\n",
    "def get_genre_ratings(trackID, userID, train_data):\n",
    "    if trackID not in track_genres or userID not in train_data:\n",
    "        return []\n",
    "\n",
    "    genre_ratings = []\n",
    "    for genreID in track_genres[trackID]:\n",
    "        if genreID in train_data[userID]:\n",
    "            genre_ratings.append(train_data[userID][genreID])\n",
    "    return genre_ratings\n",
    "\n",
    "# Calculate statistical measures for genre ratings\n",
    "def calculate_genre_stats(genre_ratings):\n",
    "    if not genre_ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "\n",
    "    num_genres = len(genre_ratings)\n",
    "    max_score = max(genre_ratings)\n",
    "    min_score = min(genre_ratings)\n",
    "    sum_score = sum(genre_ratings)\n",
    "    avg_score = np.mean(genre_ratings)\n",
    "    var_score = np.var(genre_ratings)\n",
    "    \n",
    "    return [num_genres, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Process test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor', 'NumGenres', 'MaxGenreScore', 'MinGenreScore', 'SumGenreScore', 'AvgGenreScore', 'VarGenreScore'])\n",
    "\n",
    "    for line in fTest:\n",
    "        userID, trackID = line.strip().split('|')[:2]\n",
    "\n",
    "        genre_ratings = get_genre_ratings(trackID, userID, train_data)\n",
    "        genre_stats = calculate_genre_stats(genre_ratings)\n",
    "\n",
    "        album_score, artist_score = 0, 0  # Initialize album and artist scores\n",
    "        if trackID in train_data.get(userID, {}):\n",
    "            album_score = train_data[userID][trackID]\n",
    "        if 'A' + trackID in train_data.get(userID, {}):  # Assuming 'A' prefix for artist IDs\n",
    "            artist_score = train_data[userID]['A' + trackID]\n",
    "\n",
    "        # Predict based on available scores\n",
    "        predRating = int(album_score > 0 or artist_score > 0 or any(genre_ratings))\n",
    "\n",
    "        csv_writer.writerow([f\"{userID}_{trackID}\", predRating] + genre_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae3f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "track_info_file = dataDir + 'trackData2.txt'\n",
    "output_file = dataDir + 'output2_2.csv'\n",
    "\n",
    "# Load training data\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        if userID not in train_data:\n",
    "            train_data[userID] = {}\n",
    "        train_data[userID][itemID] = int(rating)\n",
    "\n",
    "# Load track information (including genres)\n",
    "track_genres = {}\n",
    "with open(track_info_file, 'r') as fTrack:\n",
    "    for line in fTrack:\n",
    "        parts = line.strip().split('|')\n",
    "        trackID, genres = parts[0], parts[3:]\n",
    "        track_genres[trackID] = genres\n",
    "\n",
    "# Function to get genre ratings for a track\n",
    "def get_genre_ratings(trackID, userID, train_data):\n",
    "    if trackID not in track_genres or userID not in train_data:\n",
    "        return []\n",
    "\n",
    "    genre_ratings = []\n",
    "    for genreID in track_genres[trackID]:\n",
    "        if genreID in train_data[userID]:\n",
    "            genre_ratings.append(train_data[userID][genreID])\n",
    "    return genre_ratings\n",
    "\n",
    "# Calculate statistical measures for genre ratings\n",
    "def calculate_genre_stats(genre_ratings):\n",
    "    if not genre_ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "\n",
    "    num_genres = len(genre_ratings)\n",
    "    max_score = max(genre_ratings)\n",
    "    min_score = min(genre_ratings)\n",
    "    sum_score = sum(genre_ratings)\n",
    "    avg_score = np.mean(genre_ratings)\n",
    "    var_score = np.var(genre_ratings)\n",
    "    \n",
    "    return [num_genres, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Process test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])  # Write the header\n",
    "\n",
    "    for line in fTest:\n",
    "        userID, trackID = line.strip().split('|')[:2]\n",
    "\n",
    "        genre_ratings = get_genre_ratings(trackID, userID, train_data)\n",
    "        genre_stats = calculate_genre_stats(genre_ratings)\n",
    "\n",
    "        album_score, artist_score = 0, 0  # Initialize album and artist scores\n",
    "        if trackID in train_data.get(userID, {}):\n",
    "            album_score = train_data[userID][trackID]\n",
    "        if 'A' + trackID in train_data.get(userID, {}):  # Assuming 'A' prefix for artist IDs\n",
    "            artist_score = train_data[userID]['A' + trackID]\n",
    "\n",
    "        # Predict based on available scores\n",
    "        predRating = int(album_score > 0 or artist_score > 0 or any(genre_ratings))\n",
    "\n",
    "        # Write only TrackID (userID_trackID) and Predictor to the CSV\n",
    "        trackID_pred = f\"{userID}_{trackID}\"\n",
    "        csv_writer.writerow([trackID_pred, predRating])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bcb92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to calculate statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings > 0 else 0\n",
    "    var_score = np.var(ratings) if num_ratings > 0 else 0\n",
    "    \n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output2_3.csv'  # Changed the extension to .csv\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        train_data.setdefault(userID, {}).setdefault(itemID, []).append(int(rating))\n",
    "\n",
    "# Process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])  # Write the header\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        userID, trackID = parts[0], parts[1]\n",
    "        albumID, artistID = parts[2], parts[3]\n",
    "        genreIDs = parts[4:]\n",
    "\n",
    "        # Initialize ratings list with album and artist ratings if they exist\n",
    "        ratings = train_data.get(userID, {}).get(albumID, []) + \\\n",
    "                  train_data.get(userID, {}).get(artistID, [])\n",
    "\n",
    "        # Append genre ratings to the ratings list\n",
    "        for genreID in genreIDs:\n",
    "            ratings += train_data.get(userID, {}).get(genreID, [])\n",
    "\n",
    "        # Calculate stats for the ratings\n",
    "        stats = calculate_stats(ratings)\n",
    "\n",
    "        # Now, `stats` contains all the statistics needed. You can use them for further predictions.\n",
    "        # For simplicity, we will sum these stats to form a total score.\n",
    "        total_score = sum(stats)\n",
    "\n",
    "        # Decision threshold to classify as '1' or '0'\n",
    "        threshold = 100  # This should be adjusted based on analysis or cross-validation\n",
    "        prediction = 1 if total_score > threshold else 0\n",
    "\n",
    "        # Write the result to the CSV\n",
    "        trackID_pred = f\"{userID}_{trackID}\"\n",
    "        csv_writer.writerow([trackID_pred, prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b4b0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to calculate statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0, 0, 0, 0, 0, 0]  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings) if ratings else 0\n",
    "    min_score = min(ratings) if ratings else 0\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings > 0 else 0\n",
    "    var_score = np.var(ratings) if num_ratings > 0 else 0\n",
    "    \n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "track_info_file = dataDir + 'trackData2.txt'\n",
    "output_file = dataDir + 'output2_4.csv'\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 3:\n",
    "            continue  # Skip lines that don't have at least three parts\n",
    "        userID, itemID, rating = parts[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "# Load track information (including genres)\n",
    "track_info = {}\n",
    "with open(track_info_file, 'r') as fTrack:\n",
    "    for line in fTrack:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 4:\n",
    "            continue  # Ensure there is at least a trackID, albumID, artistID, and one genre\n",
    "        trackID, albumID, artistID, *genres = parts\n",
    "        track_info[trackID] = {'albumID': albumID, 'artistID': artistID, 'genres': genres}\n",
    "\n",
    "# Process test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    for line_number, line in enumerate(fTest, 1):  # Start line numbering at 1\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 2:\n",
    "            print(f\"Skipping line {line_number}: Not enough parts in test data line.\")\n",
    "            continue  # Log and skip lines that don't have at least two parts (userID and trackID)\n",
    "        userID, trackID = parts[0], parts[1]\n",
    "\n",
    "        # Default prediction if no track info\n",
    "        prediction = 0\n",
    "        stats = [0] * 6\n",
    "\n",
    "        # If trackID is in track_info, calculate predictions\n",
    "        if trackID in track_info:\n",
    "            track_data = track_info[trackID]\n",
    "            albumID, artistID = track_data['albumID'], track_data['artistID']\n",
    "            genres = track_data['genres']\n",
    "\n",
    "            # Initialize ratings list with album and artist ratings\n",
    "            ratings = [train_data.get(userID, {}).get(albumID, 0),\n",
    "                       train_data.get(userID, {}).get(artistID, 0)]\n",
    "            \n",
    "            # Append genre ratings to the ratings list\n",
    "            for genreID in genres:\n",
    "                ratings.append(train_data.get(userID, {}).get(genreID, 0))\n",
    "\n",
    "            # Filter out zero ratings and calculate stats for the remaining ratings\n",
    "            non_zero_ratings = list(filter(lambda x: x > 0, ratings))\n",
    "            stats = calculate_stats(non_zero_ratings)\n",
    "\n",
    "            # Use a simple sum of stats for prediction. Customize this logic as needed.\n",
    "            total_score = sum(stats)\n",
    "\n",
    "            # Threshold to decide on the prediction value. This may need tuning.\n",
    "            threshold = sum(stats) / 2\n",
    "            prediction = 1 if total_score >= threshold else 0\n",
    "\n",
    "        # Write the result to the CSV\n",
    "        csv_writer.writerow([f\"{userID}_{trackID}\", prediction])\n",
    "\n",
    "# No lines should be skipped due to missing track information anymore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a947655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to calculate statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings else 0\n",
    "    var_score = np.var(ratings) if num_ratings else 0\n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Function to normalize ratings\n",
    "def normalize(ratings):\n",
    "    max_rating = max(ratings) if ratings else 1\n",
    "    return [float(rating) / max_rating for rating in ratings]\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open('trainItem2.txt', 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 3:\n",
    "            continue  # Skip incomplete lines\n",
    "        userID, itemID, rating = parts[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "# Load additional data (albums, artists, genres)\n",
    "album_info = {}\n",
    "with open('albumData2.txt', 'r') as fAlbum:\n",
    "    for line in fAlbum:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 2:\n",
    "            continue  # Skip incomplete lines\n",
    "        albumID, artistID, *genreIDs = parts\n",
    "        album_info[albumID] = {'artistID': artistID, 'genreIDs': genreIDs}\n",
    "\n",
    "artist_info = {}\n",
    "with open('artistData2.txt', 'r') as fArtist:\n",
    "    for line in fArtist:\n",
    "        artistID = line.strip()\n",
    "        artist_info[artistID] = {'genreIDs': []}  # Assuming no direct genre info for artists\n",
    "\n",
    "genre_info = set()\n",
    "with open('genreData2.txt', 'r') as fGenre:\n",
    "    for line in fGenre:\n",
    "        genre_info.add(line.strip())\n",
    "\n",
    "# ... [previous code remains unchanged]\n",
    "\n",
    "# Process test data and write predictions\n",
    "with open('testTrack_hierarchy.txt', 'r') as fTest, open('output.csv', 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 2:\n",
    "            continue  # Skip incomplete lines\n",
    "        userID, trackID, *rest = parts\n",
    "\n",
    "        # If we do not have this user in training data, we skip prediction\n",
    "        if userID not in train_data:\n",
    "            continue\n",
    "\n",
    "        # Gather all the genreIDs related to the track through album and artist\n",
    "        genreIDs = set()\n",
    "        for itemID in rest:\n",
    "            if itemID in album_info:\n",
    "                genreIDs.update(album_info[itemID]['genreIDs'])\n",
    "            elif itemID in artist_info:\n",
    "                genreIDs.update(artist_info[itemID]['genreIDs'])\n",
    "            elif itemID in genre_info:\n",
    "                genreIDs.add(itemID)\n",
    "        \n",
    "        # Get ratings for all genres related to the track\n",
    "        genre_ratings = [train_data[userID].get(genreID, 0) for genreID in genreIDs]\n",
    "        # Normalize and calculate stats for genre ratings\n",
    "        genre_stats = calculate_stats(normalize(genre_ratings))\n",
    "\n",
    "        # Prediction logic...\n",
    "        # For the purpose of this example, we use a simple sum of stats\n",
    "        total_score = sum(genre_stats)\n",
    "\n",
    "        # Threshold to decide on the prediction value (this needs tuning)\n",
    "        threshold = 100\n",
    "        prediction = 1 if total_score >= threshold else 0\n",
    "\n",
    "        # Write the result to CSV\n",
    "        trackID_pred = f\"{userID}_{trackID}\"\n",
    "        csv_writer.writerow([trackID_pred, prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232e1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to calculate statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings else 0\n",
    "    var_score = np.var(ratings) if num_ratings else 0\n",
    "    \n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Placeholder for the actual logic to get genre scores for a track\n",
    "def get_genre_scores(trackID, userID, train_data, track_info):\n",
    "    genre_scores = []\n",
    "    if trackID in track_info:\n",
    "        genres = track_info[trackID]['genres']  # Get the list of genres associated with the track\n",
    "        for genreID in genres:\n",
    "            score = train_data.get(userID, {}).get(genreID, 0)\n",
    "            if score > 0:  # Consider only non-zero scores\n",
    "                genre_scores.append(score)\n",
    "    return genre_scores\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "track_info_file = dataDir + 'trackData2.txt'\n",
    "output_file = dataDir + 'output2_6.csv'\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 3:\n",
    "            continue  # Skip lines that don't have at least three parts\n",
    "        userID, itemID, rating = parts[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "# Load track information (including genres)\n",
    "track_info = {}\n",
    "with open(track_info_file, 'r') as fTrack:\n",
    "    for line in fTrack:\n",
    "        parts = line.strip().split('|')\n",
    "        trackID, albumID, artistID, *genres = parts\n",
    "        track_info[trackID] = {'albumID': albumID, 'artistID': artistID, 'genres': genres}\n",
    "\n",
    "# Process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    lastUserID = None\n",
    "    trackID_vec = []\n",
    "    track_scores = []\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 4:\n",
    "            continue  # Skip lines that don't have enough data\n",
    "        userID, trackID, albumID, artistID = parts[:4]\n",
    "\n",
    "        if userID != lastUserID and lastUserID is not None:\n",
    "            # Rank and write predictions for the previous user's tracks\n",
    "            ranked_scores = sorted(zip(trackID_vec, track_scores), key=lambda x: x[1], reverse=True)\n",
    "            for i, (trackID, _) in enumerate(ranked_scores):\n",
    "                pred = 1 if i < 3 else 0  # Mark top 3 tracks as \"1\" and others as \"0\"\n",
    "                csv_writer.writerow([f\"{lastUserID}_{trackID}\", pred])\n",
    "            trackID_vec = []\n",
    "            track_scores = []\n",
    "\n",
    "        trackID_vec.append(trackID)\n",
    "\n",
    "        album_score = train_data.get(userID, {}).get(albumID, 0)\n",
    "        artist_score = train_data.get(userID, {}).get(artistID, 0)\n",
    "        genre_scores = get_genre_scores(trackID, userID, train_data, track_info)\n",
    "        genre_stats = calculate_stats(genre_scores)\n",
    "\n",
    "        track_score = album_score + artist_score + sum(genre_stats)  # Combine scores\n",
    "        track_scores.append(track_score)\n",
    "\n",
    "        lastUserID = userID\n",
    "\n",
    "    # Handle the last user after the loop ends\n",
    "    if trackID_vec:\n",
    "        ranked_scores = sorted(zip(trackID_vec, track_scores), key=lambda x: x[1], reverse=True)\n",
    "        for i, (trackID, _) in enumerate(ranked_scores):\n",
    "            pred = 1 if i < 3 else 0  # Mark top 3 tracks as \"1\" and others as \"0\"\n",
    "            csv_writer.writerow([f\"{lastUserID}_{trackID}\", pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85cc93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Define your function for calculating statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings else 0\n",
    "    var_score = np.var(ratings) if num_ratings else 0\n",
    "    \n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Placeholder function to simulate or derive genre scores for a track\n",
    "def get_genre_scores(trackID, userID, train_data, track_info):\n",
    "    genre_scores = []\n",
    "    if trackID in track_info:\n",
    "        genres = track_info[trackID]['genres']  # List of genres for the track\n",
    "        for genreID in genres:\n",
    "            score = train_data.get(userID, {}).get(genreID, 0)\n",
    "            if score > 0:  # Only consider non-zero scores\n",
    "                genre_scores.append(score)\n",
    "    return genre_scores\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "track_info_file = dataDir + 'trackData2.txt'\n",
    "output_file = dataDir + 'output2_6_5.csv'\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 3:\n",
    "            continue  # Skip lines with insufficient data\n",
    "        userID, itemID, rating = parts[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "# Load track information (including genres)\n",
    "track_info = {}\n",
    "with open(track_info_file, 'r') as fTrack:\n",
    "    for line in fTrack:\n",
    "        parts = line.strip().split('|')\n",
    "        trackID, albumID, artistID, *genres = parts\n",
    "        track_info[trackID] = {'albumID': albumID, 'artistID': artistID, 'genres': genres}\n",
    "\n",
    "# Process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    lastUserID = None\n",
    "    processed_trackIDs = set()  # Track processed TrackIDs for each user\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 4:\n",
    "            continue  # Skip lines with insufficient data\n",
    "        userID, trackID, albumID, artistID = parts[:4]\n",
    "\n",
    "        kaggle_trackID = f\"{userID}_{trackID}\"  # Format used by Kaggle\n",
    "\n",
    "        if userID != lastUserID:\n",
    "            processed_trackIDs.clear()  # Reset for a new user\n",
    "\n",
    "        if kaggle_trackID in processed_trackIDs:\n",
    "            continue  # Skip duplicate TrackIDs for the same user\n",
    "\n",
    "        processed_trackIDs.add(kaggle_trackID)\n",
    "\n",
    "        # Calculation logic for album, artist, and genre scores\n",
    "        album_score = train_data.get(userID, {}).get(albumID, 0)\n",
    "        artist_score = train_data.get(userID, {}).get(artistID, 0)\n",
    "        genre_scores = get_genre_scores(trackID, userID, train_data, track_info)\n",
    "        genre_stats = calculate_stats(genre_scores)\n",
    "\n",
    "        # Example scoring logic combining album, artist, and genre statistics\n",
    "        track_score = album_score + artist_score + sum(genre_stats)\n",
    "\n",
    "        # Example threshold for prediction; you may need to adjust this\n",
    "        prediction = 1 if track_score >= 30 else 0\n",
    "\n",
    "        # Write the result to the CSV\n",
    "        csv_writer.writerow([kaggle_trackID, prediction])\n",
    "\n",
    "        lastUserID = userID  # Update the last processed userID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e51c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6\n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings else 0\n",
    "    var_score = np.var(ratings) if num_ratings else 0\n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "def get_genre_scores(trackID, userID, train_data, track_info):\n",
    "    genre_scores = []\n",
    "    if trackID in track_info:\n",
    "        genres = track_info[trackID]['genres']\n",
    "        for genreID in genres:\n",
    "            score = train_data.get(userID, {}).get(genreID, 0)\n",
    "            if score > 0:\n",
    "                genre_scores.append(score)\n",
    "    return genre_scores\n",
    "\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "track_info_file = dataDir + 'trackData2.txt'\n",
    "output_file = dataDir + 'output_weighted_2.csv'\n",
    "\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        userID, itemID, rating = parts[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "track_info = {}\n",
    "with open(track_info_file, 'r') as fTrack:\n",
    "    for line in fTrack:\n",
    "        parts = line.strip().split('|')\n",
    "        trackID, albumID, artistID, *genres = parts\n",
    "        track_info[trackID] = {'albumID': albumID, 'artistID': artistID, 'genres': genres}\n",
    "\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    lastUserID = None\n",
    "    processed_trackIDs = set()\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        userID, trackID, albumID, artistID = parts[:4]\n",
    "        kaggle_trackID = f\"{userID}_{trackID}\"\n",
    "\n",
    "        if userID != lastUserID:\n",
    "            processed_trackIDs.clear()\n",
    "\n",
    "        if kaggle_trackID in processed_trackIDs:\n",
    "            continue\n",
    "\n",
    "        processed_trackIDs.add(kaggle_trackID)\n",
    "\n",
    "        # Weights\n",
    "        album_weight = 0.6\n",
    "        artist_weight = 0.4\n",
    "        genre_weight = 0.2\n",
    "\n",
    "        album_score = train_data.get(userID, {}).get(albumID, 0) * album_weight\n",
    "        artist_score = train_data.get(userID, {}).get(artistID, 0) * artist_weight\n",
    "        genre_scores = get_genre_scores(trackID, userID, train_data, track_info)\n",
    "        genre_stats = calculate_stats(genre_scores)\n",
    "        genre_score = sum(genre_stats) * genre_weight  # Aggregate genre score\n",
    "\n",
    "        # Combined weighted score\n",
    "        track_score = album_score + artist_score + genre_score\n",
    "\n",
    "        prediction = 1 if track_score >= 100 else 0  # Adjust threshold as needed\n",
    "\n",
    "        csv_writer.writerow([kaggle_trackID, prediction])\n",
    "\n",
    "        lastUserID = userID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2d026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1af33dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to calculate statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings > 0 else 0\n",
    "    var_score = np.var(ratings) if num_ratings > 0 else 0\n",
    "    \n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output2_3_1.csv'  # Changed the extension to .csv\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        train_data.setdefault(userID, {}).setdefault(itemID, []).append(int(rating))\n",
    "\n",
    "# Process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])  # Write the header\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        userID, trackID = parts[0], parts[1]\n",
    "        albumID, artistID = parts[2], parts[3]\n",
    "        genreIDs = parts[4:]\n",
    "\n",
    "        # Initialize ratings list with album and artist ratings if they exist\n",
    "        ratings = train_data.get(userID, {}).get(albumID, []) + \\\n",
    "                  train_data.get(userID, {}).get(artistID, [])\n",
    "\n",
    "        # Append genre ratings to the ratings list\n",
    "        for genreID in genreIDs:\n",
    "            ratings += train_data.get(userID, {}).get(genreID, [])\n",
    "\n",
    "        # Calculate stats for the ratings\n",
    "        stats = calculate_stats(ratings)\n",
    "\n",
    "        # Now, `stats` contains all the statistics needed. You can use them for further predictions.\n",
    "        # For simplicity, we will sum these stats to form a total score.\n",
    "        total_score = sum(stats)\n",
    "\n",
    "        # Decision threshold to classify as '1' or '0'\n",
    "        threshold = 100  # This should be adjusted based on analysis or cross-validation\n",
    "        prediction = 1 if total_score > threshold else 0\n",
    "\n",
    "        # Write the result to the CSV\n",
    "        trackID_pred = f\"{userID}_{trackID}\"\n",
    "        csv_writer.writerow([trackID_pred, prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95de9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to calculate statistical measures for ratings\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings > 0 else 0\n",
    "    var_score = np.var(ratings) if num_ratings > 0 else 0\n",
    "    \n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output2_7.csv'  # Changed the extension to .csv\n",
    "\n",
    "# Load the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "# Process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])  # Write the header\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        userID, trackID = parts[0], parts[1]\n",
    "        albumID, artistID = parts[2], parts[3]\n",
    "        genreIDs = parts[4:]\n",
    "\n",
    "        # Initialize ratings list with album and artist ratings if they exist\n",
    "        album_artist_ratings = []\n",
    "        if albumID in train_data.get(userID, {}):\n",
    "            album_artist_ratings.append(train_data[userID][albumID])\n",
    "        if artistID in train_data.get(userID, {}):\n",
    "            album_artist_ratings.append(train_data[userID][artistID])\n",
    "\n",
    "        # Scan through all genres and collect their ratings\n",
    "        genre_ratings = []\n",
    "        for genreID in genreIDs:\n",
    "            if genreID in train_data.get(userID, {}):\n",
    "                genre_ratings.append(train_data[userID][genreID])\n",
    "\n",
    "        # Combine album/artist ratings with genre ratings for statistical calculations\n",
    "        all_ratings = album_artist_ratings + genre_ratings\n",
    "        stats = calculate_stats(all_ratings)\n",
    "\n",
    "        # Use 'stats' for further predictions. For simplicity, we sum these stats to form a total score.\n",
    "        total_score = sum(stats)\n",
    "\n",
    "        # Decision threshold to classify as '1' or '0'\n",
    "        threshold = 100  # This should be adjusted based on analysis or cross-validation\n",
    "        prediction = 1 if total_score > threshold else 0\n",
    "\n",
    "        # Write the result to the CSV\n",
    "        trackID_pred = f\"{userID}_{trackID}\"\n",
    "        csv_writer.writerow([trackID_pred, prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e530131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def calculate_stats(ratings):\n",
    "    if not ratings:\n",
    "        return [0] * 6  # Return zeros if no ratings\n",
    "    \n",
    "    num_ratings = len(ratings)\n",
    "    max_score = max(ratings, default=0)\n",
    "    min_score = min(ratings, default=0)\n",
    "    sum_score = sum(ratings)\n",
    "    avg_score = sum_score / num_ratings if num_ratings > 0 else 0\n",
    "    #var_score = np.var(ratings) if num_ratings > 0 else 0\n",
    "    #return [num_ratings, max_score, min_score, sum_score, avg_score, var_score]\n",
    "    std_dev = np.std(ratings) if ratings else 0\n",
    "    return [num_ratings, max_score, min_score, sum_score, avg_score, std_dev]\n",
    "\n",
    "    \n",
    "\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output2_8_3.csv'\n",
    "\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        train_data.setdefault(userID, {})[itemID] = int(rating)\n",
    "\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    for line in fTest:\n",
    "        parts = line.strip().split('|')\n",
    "        userID, trackID = parts[0], parts[1]\n",
    "        kaggle_trackID = f\"{userID}_{trackID}\"\n",
    "\n",
    "        albumID, artistID = parts[2], parts[3]\n",
    "        genreIDs = parts[4:]\n",
    "\n",
    "        # Initialize ratings list with album and artist ratings if they exist\n",
    "        ratings = []\n",
    "        if albumID in train_data.get(userID, {}):\n",
    "            ratings.append(train_data[userID][albumID])\n",
    "        if artistID in train_data.get(userID, {}):\n",
    "            ratings.append(train_data[userID][artistID])\n",
    "\n",
    "        # Append genre ratings to the ratings list\n",
    "        for genreID in genreIDs:\n",
    "            if genreID in train_data.get(userID, {}):\n",
    "                ratings.append(train_data[userID][genreID])\n",
    "\n",
    "        # Calculate stats for the ratings\n",
    "        stats = calculate_stats(ratings)\n",
    "\n",
    "        # Combine the statistics to form a total score for the track\n",
    "        total_score = sum(stats)\n",
    "\n",
    "        # Decision threshold to classify as '1' or '0'\n",
    "        threshold = 200  # Adjust based on validation\n",
    "        prediction = 1 if total_score > threshold else 0\n",
    "\n",
    "        # Write the result to the CSV\n",
    "        csv_writer.writerow([kaggle_trackID, prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950986d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
