{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2816b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy\n",
    "\n",
    "dataDir='C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test=dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train=dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file= dataDir + 'output1.txt'\n",
    "\n",
    "fTest= open(file_name_test, 'r')\n",
    "fTrain=open(file_name_train, 'r')\n",
    "Trainline= fTrain.readline()\n",
    "fOut = open(output_file, 'w')\n",
    "\n",
    "trackID_vec=[0]*6\n",
    "albumID_vec=[0]*6\n",
    "artistID_vec=[0]*6\n",
    "lastUserID=-1\n",
    "\n",
    "user_rating_inTrain=numpy.zeros(shape=(6,3))\n",
    "\n",
    "for line in fTest:\n",
    "\tarr_test=line.strip().split('|')\n",
    "\tuserID= arr_test[0]\n",
    "\ttrackID= arr_test[1]\n",
    "\talbumID= arr_test[2]\n",
    "\tartistID=arr_test[3]\n",
    "\n",
    "\tif userID!= lastUserID:\n",
    "\t\tii=0\n",
    "\t\tuser_rating_inTrain=numpy.zeros(shape=(6,3))\n",
    "\n",
    "\ttrackID_vec[ii]=trackID\n",
    "\talbumID_vec[ii]=albumID\n",
    "\tartistID_vec[ii]=artistID\n",
    "\tii=ii+1\n",
    "\tlastUserID=userID\n",
    "\n",
    "\tif ii==6 : \n",
    "\t\twhile (Trainline):\n",
    "\t\t# for Trainline in fTrain:\n",
    "\t\t\tarr_train = Trainline.strip().split('|')\n",
    "\t\t\ttrainUserID=arr_train[0]\n",
    "\t\t\ttrainItemID=arr_train[1]\n",
    "\t\t\ttrainRating=arr_train[2]\n",
    "\t\t\tTrainline=fTrain.readline()\t\t\n",
    "\n",
    "\t\t\tif trainUserID< userID:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif trainUserID== userID:\t\t\t\t\n",
    "\t\t\t\tfor nn in range(0, 6):\n",
    "\t\t\t\t\tif trainItemID==albumID_vec[nn]:\n",
    "\t\t\t\t\t\tuser_rating_inTrain[nn, 0]=trainRating\n",
    "\t\t\t\t\tif trainItemID==artistID_vec[nn]:\n",
    "\t\t\t\t\t\tuser_rating_inTrain[nn, 1]=trainRating\n",
    "\t\t\tif trainUserID> userID:\n",
    "\t\t\t\tfor nn in range(0, 6):\n",
    "\t\t\t\t\toutStr=str(userID) + '|' + str(trackID_vec[nn])+ '|' + str(user_rating_inTrain[nn,0]) + '|' + str(user_rating_inTrain[nn, 1])\n",
    "\t\t\t\t\tfOut.write(outStr + '\\n')\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\n",
    "fTest.close()\n",
    "fTrain.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43e31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output1.txt'\n",
    "\n",
    "# Load training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        if userID not in train_data:\n",
    "            train_data[userID] = {}\n",
    "        # Store ratings by album and artist ID\n",
    "        train_data[userID][itemID] = int(rating)\n",
    "\n",
    "# Process test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w') as fOut:\n",
    "    lastUserID = None  # Track the last user ID processed\n",
    "    trackID_vec = []  # Initialize the track ID vector for each user\n",
    "\n",
    "    for line in fTest:\n",
    "        arr_test = line.strip().split('|')\n",
    "        if len(arr_test) < 4:\n",
    "            continue  # Skip if line doesn't have enough data\n",
    "        userID, trackID, albumID, artistID = arr_test[:4]\n",
    "\n",
    "        # Reset trackID_vec for a new user\n",
    "        if userID != lastUserID:\n",
    "            if lastUserID is not None:\n",
    "                # Write predictions for the previous user's tracks\n",
    "                for i, predRating in enumerate(predRatings):\n",
    "                    outStr = f\"{lastUserID}|{trackID_vec[i]}|{int(predRating > 0)}\\n\"  # Convert to 0 or 1 based on whether a rating exists\n",
    "                    fOut.write(outStr)\n",
    "\n",
    "            trackID_vec = [trackID]  # Start a new list for the new user\n",
    "            predRatings = np.zeros(6)  # Reset predicted ratings for the new user\n",
    "        else:\n",
    "            trackID_vec.append(trackID)  # Append trackID for the same user\n",
    "\n",
    "        # Check if the user exists in the training data\n",
    "        if userID in train_data:\n",
    "            user_ratings = train_data[userID]\n",
    "\n",
    "            # Predict based on album or artist rating, if available\n",
    "            if albumID in user_ratings:\n",
    "                predRatings[len(trackID_vec) - 1] = user_ratings[albumID]\n",
    "            elif artistID in user_ratings:\n",
    "                predRatings[len(trackID_vec) - 1] = user_ratings[artistID]\n",
    "\n",
    "        lastUserID = userID  # Update the last user ID processed\n",
    "\n",
    "    # Write predictions for the last user in the file\n",
    "    for i, predRating in enumerate(predRatings):\n",
    "        outStr = f\"{userID}|{trackID_vec[i]}|{int(predRating > 0)}\\n\"\n",
    "        fOut.write(outStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999b9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output1.csv'  # Changed the extension to .csv\n",
    "\n",
    "# Loading the training data into a dictionary\n",
    "train_data = {}\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        if userID not in train_data:\n",
    "            train_data[userID] = {}\n",
    "        train_data[userID][itemID] = int(rating)\n",
    "\n",
    "# then we process the test data and write predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])  # Into the csv file we will add the header\n",
    "\n",
    "    lastUserID = None  # Track the last user ID processed\n",
    "    trackID_vec = []  # Initialize the track ID vector for each user\n",
    "\n",
    "    for line in fTest:\n",
    "        arr_test = line.strip().split('|')\n",
    "        if len(arr_test) < 4:\n",
    "            continue  # we will skip if  then line doesn't have enough data\n",
    "        userID, trackID, albumID, artistID = arr_test[:4]   # only considering these 4 entities \n",
    "\n",
    "        # Reset trackID_vec for a new user\n",
    "        if userID != lastUserID:\n",
    "            if lastUserID is not None:\n",
    "                # Write predictions for the previous user's tracks\n",
    "                for i, predRating in enumerate(predRatings):\n",
    "                    trackID_pred = f\"{lastUserID}_{trackID_vec[i]}\"\n",
    "                    csv_writer.writerow([trackID_pred, int(predRating > 0)]) \n",
    "\n",
    "            trackID_vec = [trackID]  # Start a new list for the new user\n",
    "            predRatings = np.zeros(6)  # Reset predicted ratings for the new user\n",
    "        else:\n",
    "            trackID_vec.append(trackID)  # Append trackID for the same user\n",
    "\n",
    "        # Check if the user exists in the training data\n",
    "        if userID in train_data:\n",
    "            user_ratings = train_data[userID]\n",
    "\n",
    "            # Predict based on album or artist rating, if available\n",
    "            if albumID in user_ratings:\n",
    "                predRatings[len(trackID_vec) - 1] = user_ratings[albumID]\n",
    "            elif artistID in user_ratings:\n",
    "                predRatings[len(trackID_vec) - 1] = user_ratings[artistID]\n",
    "\n",
    "        lastUserID = userID  # Update the last user ID processed\n",
    "\n",
    "    # Write predictions for the last user in the file\n",
    "    for i, predRating in enumerate(predRatings):\n",
    "        trackID_pred = f\"{userID}_{trackID_vec[i]}\"\n",
    "        csv_writer.writerow([trackID_pred, int(predRating > 0)])  # Write to CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6339e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navne\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39884\\1732984744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Precompute similarities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0msimilarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_similarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Process test data and make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39884\\1732984744.py\u001b[0m in \u001b[0;36mcompute_similarities\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mratings1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcommon_items\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mratings2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcommon_items\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0msimilarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0msimilarities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   4014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4015\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4016\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x and y must have length at least 2.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4018\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.stats import pearsonr\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up file paths\n",
    "dataDir = 'C:/Users/navne/Python Files/Data Acquisition BIA 627/Final Project/'\n",
    "file_name_test = dataDir + 'testTrack_hierarchy.txt'\n",
    "file_name_train = dataDir + 'trainIdx2_matrix.txt'\n",
    "output_file = dataDir + 'output1_2.csv'\n",
    "\n",
    "# Load training data\n",
    "train_data = defaultdict(dict)\n",
    "with open(file_name_train, 'r') as fTrain:\n",
    "    for line in fTrain:\n",
    "        userID, itemID, rating = line.strip().split('|')[:3]\n",
    "        train_data[userID][itemID] = int(rating)\n",
    "\n",
    "# Compute user similarities\n",
    "def compute_similarities(train_data):\n",
    "    similarities = {}\n",
    "    users = list(train_data.keys())\n",
    "    for i, user1 in enumerate(users):\n",
    "        for user2 in users[i+1:]:\n",
    "            # Compute Pearson correlation coefficient between user1 and user2\n",
    "            common_items = set(train_data[user1]).intersection(set(train_data[user2]))\n",
    "            if len(common_items) > 0:\n",
    "                ratings1 = [train_data[user1][item] for item in common_items]\n",
    "                ratings2 = [train_data[user2][item] for item in common_items]\n",
    "                similarity, _ = pearsonr(ratings1, ratings2)\n",
    "                similarities[(user1, user2)] = similarity\n",
    "    return similarities\n",
    "\n",
    "# Predict rating\n",
    "def predict_rating(user, item, train_data, similarities, k=10):\n",
    "    # Find k most similar users who have rated this item\n",
    "    scores = []\n",
    "    for (user1, user2), similarity in similarities.items():\n",
    "        other_user = user2 if user1 == user else user1\n",
    "        if item in train_data[other_user]:\n",
    "            scores.append((similarity, train_data[other_user][item]))\n",
    "    scores.sort(reverse=True)\n",
    "    scores = scores[:k]  # Keep top k scores\n",
    "    \n",
    "    # Compute weighted average\n",
    "    if scores:\n",
    "        weighted_sum = sum(similarity * rating for similarity, rating in scores)\n",
    "        sum_of_weights = sum(abs(similarity) for similarity, _ in scores)\n",
    "        return weighted_sum / sum_of_weights if sum_of_weights > 0 else 0\n",
    "    return 0  # Fallback if no similar users have rated this item\n",
    "\n",
    "# Precompute similarities\n",
    "similarities = compute_similarities(train_data)\n",
    "\n",
    "# Process test data and make predictions\n",
    "with open(file_name_test, 'r') as fTest, open(output_file, 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow(['TrackID', 'Predictor'])\n",
    "\n",
    "    for line in fTest:\n",
    "        userID, trackID, _, _ = line.strip().split('|')[:4]\n",
    "        predRating = predict_rating(userID, trackID, train_data, similarities)\n",
    "        csv_writer.writerow([f\"{userID}_{trackID}\", int(predRating >= 0.5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
